{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook is use to collect the first datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import unicodedata\n",
    "import re\n",
    "import googlemaps\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neighborhood São Paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_neighborhood = 'https://www.estadosecapitaisdobrasil.com/listas/lista-dos-bairros-de-sao-paulo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all neighborhood in São Paulo\n",
    "response = requests.get(url_neighborhood)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html)\n",
    "neighborhood_sp = []\n",
    "for neighb in soup.find_all('li')[24:]:\n",
    "    neighborhood_sp.append(unicodedata.normalize('NFKD', neighb.text).encode('ASCII', 'ignore').decode('utf-8').strip().lower().replace(' ','+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agua+rasa', 'alto+de+pinheiros', 'anhanguera', 'aricanduva', 'artur+alvim', 'barra+funda', 'bela+vista', 'belem', 'bom+retiro', 'brasilandia', 'butanta', 'cachoeirinha', 'cambuci', 'campo+belo', 'campo+grande', 'campo+limpo', 'cangaiba', 'capao+redondo', 'carrao', 'casa+verde', 'cidade+ademar', 'cidade+dutra', 'cidade+lider', 'cidade+lider', 'cidade+tiradentes', 'consolacao', 'cursino', 'ermelino+matarazzo', 'freguesia+do+o', 'grajau', 'guaianases', 'iguatemi', 'ipiranga', 'itaim+bibi', 'itaim+paulista', 'itaquera', 'jabaquara', 'jacana', 'jaguara', 'jaguare', 'jaragua', 'jardim+angela', 'jardim+helena', 'jardim+paulista', 'jardim+sao+luis', 'lapa', 'liberdade', 'limao', 'mandaqui', 'marsilac', 'moema', 'mooca', 'morumbi', 'parelheiros', 'pari', 'parque+do+carmo', 'penha', 'perdizes', 'pinheiros', 'ponte+rasa', 'raposo+tavares', 'republica', 'rio+pequeno', 'sacoma', 'santa+cecilia', 'santana', 'santo+amaro', 'sao+domingos', 'sao+lucas', 'sao+mateus', 'sao+miguel+paulista', 'sao+rafael', 'sapopemba', 'saude', 'se', 'tatuape', 'tremembe', 'tucuruvi', 'vila+andrade', 'vila+curuca', 'vila+formosa', 'vila+guilherme', 'vila+jacui', 'vila+leopoldina', 'vila+maria', 'vila+mariana', 'vila+matilde', 'vila+medeiros', 'vila+prudente', 'vila+sonia']\n"
     ]
    }
   ],
   "source": [
    "print(neighborhood_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# streets São Paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code get the streets from neighborhood selected previously\n",
    "df_street = pd.DataFrame()\n",
    "for neighborhood in neighborhood_sp:\n",
    "    for pag in range(1,10):\n",
    "        try:\n",
    "            url = fr'https://cep.guiamais.com.br/busca/{neighborhood}-sao+paulo-sp?page={pag}'\n",
    "            response = requests.get(url)\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html)\n",
    "            table = soup.find_all('table')\n",
    "            data = pd.read_html(str(table))[0]\n",
    "            df_street = df_street.append(data, ignore_index=True)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOGRADOURO</th>\n",
       "      <th>BAIRRO</th>\n",
       "      <th>CIDADE/ESTADO</th>\n",
       "      <th>BAIRRO.1</th>\n",
       "      <th>CEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rua Areas</td>\n",
       "      <td>Água Rasa</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>Água Rasa, São Paulo, SP</td>\n",
       "      <td>03179-020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rua Barão de Penedo</td>\n",
       "      <td>Água Rasa</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>Água Rasa, São Paulo, SP</td>\n",
       "      <td>03179-070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rua Barão de Penedo 107</td>\n",
       "      <td>Água Rasa</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>Água Rasa, São Paulo, SP</td>\n",
       "      <td>03175-901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rua Barão de Penedo 107</td>\n",
       "      <td>Água Rasa</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>Água Rasa, São Paulo, SP</td>\n",
       "      <td>03179-900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rua Capitão João Rosa da Cruz</td>\n",
       "      <td>Água Rasa</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>Água Rasa, São Paulo, SP</td>\n",
       "      <td>03179-080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LOGRADOURO     BAIRRO  CIDADE/ESTADO  \\\n",
       "0                      Rua Areas  Água Rasa  São Paulo, SP   \n",
       "1            Rua Barão de Penedo  Água Rasa  São Paulo, SP   \n",
       "2        Rua Barão de Penedo 107  Água Rasa  São Paulo, SP   \n",
       "3        Rua Barão de Penedo 107  Água Rasa  São Paulo, SP   \n",
       "4  Rua Capitão João Rosa da Cruz  Água Rasa  São Paulo, SP   \n",
       "\n",
       "                   BAIRRO.1        CEP  \n",
       "0  Água Rasa, São Paulo, SP  03179-020  \n",
       "1  Água Rasa, São Paulo, SP  03179-070  \n",
       "2  Água Rasa, São Paulo, SP  03175-901  \n",
       "3  Água Rasa, São Paulo, SP  03179-900  \n",
       "4  Água Rasa, São Paulo, SP  03179-080  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_street.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe \n",
    "df_street.to_csv('../data/raw-data/df_street.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quinto Andar - apartment for rent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming street to search apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search works better with the pattern street-street-neighborhoodapartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_research_neighborhood(row):\n",
    "    row = unidecode.unidecode(row).lower()\n",
    "    row = row.replace(' ','-')\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_street(row):\n",
    "    row = unidecode.unidecode(row).lower()\n",
    "    row = row.replace('- ate ','')\n",
    "    row = row.replace(' - lado impar','')\n",
    "    row = row.replace(' - lado par','')\n",
    "    row = row.replace(' ','-')\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_street_variable(row):\n",
    "    row = row.replace('--de-','')\n",
    "    row = row.split('-a-')[0]\n",
    "    row = row.split('-ao-')[0]   \n",
    "    row = row.replace('/','-')\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_street['BAIRRO'] = df_street['BAIRRO'].apply(transform_research_neighborhood)\n",
    "df_street['LOGRADOURO'] = df_street['LOGRADOURO'].apply(transform_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_streets_search = df_street['LOGRADOURO'] + '-' + df_street['BAIRRO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_streets_search = qa_streets_search.apply(clean_street_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a list with streets to search in quinto andar website\n",
    "list_streets = []\n",
    "for rua in range(qa_streets_search.size):\n",
    "    list_streets.append(qa_streets_search[rua])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraping id aparaments using photos name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the website contain a card with basic descriptions. \n",
    "#The image in card contains a ID that can be used to scraping more data in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_apartment_photo = []\n",
    "\n",
    "for streets in list_streets:\n",
    "    url = f'https://www.quintoandar.com.br/alugar/imovel/{streets}-sao-paulo-sp-brasil/'\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    #advertising [2], [10] ignore them\n",
    "    for tag_card in [x for x in range(18) if x != 2 and x != 10]:\n",
    "        try:\n",
    "            cards = soup.find_all('div', attrs={'class':'sc-1qwl1yl-0 igVsBW'})[tag_card]\n",
    "            \n",
    "            photo = cards.find('div' ,attrs={'class':'sc-1nwwxw0-0 drvPOq'}).img['src']\n",
    "\n",
    "\n",
    "            apartment = {  \n",
    "                            'photo': photo\n",
    "                         }\n",
    "\n",
    "            list_apartment_photo.append(apartment)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_id = pd.DataFrame(list_apartment_photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_id(row):\n",
    "    row = row.split('/img/med/')[1]\n",
    "    return row.split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_id['ID'] = df_qa_id['photo'].apply(pick_id)\n",
    "df_qa_id = df_qa_id['ID']\n",
    "df_qa_id = df_qa_id.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the dataframe\n",
    "df_qa_id.to_csv('../data/raw-data/df_qa_id.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraping rent apartment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap from quinto andar website, cointains value and features from apartment\n",
    "#it uses the ID collected previously to obtain more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_id = pd.read_csv(r'data/df_qa_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_apartment = []\n",
    "\n",
    "for cod in df_qa_id['ID']:\n",
    "    url = f'https://www.quintoandar.com.br/imovel/{cod}'\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        endereco = re.findall(r'address:(.*)availabilityType',soup.text)\n",
    "        endereco = endereco[0].replace('},\"e\"],','')\n",
    "        endereco = endereco.replace('[{','')\n",
    "        endereco = endereco.split(',')            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        tipo_imovel = soup.find('h1').text\n",
    "        logradouro = soup.find('p',attrs={'class':'sc-bdVaJa gZyMJB'}).text.split(',')[0]     \n",
    "        bairro = soup.find('p',attrs={'class':'sc-bdVaJa gZyMJB'}).text.split(',')[1]                \n",
    "        cidade = soup.find('p',attrs={'class':'sc-bdVaJa gZyMJB'}).text.split(',')[2]         \n",
    "        metragem = soup.find_all('span',attrs={'class':'sc-bdVaJa eNFcTE'})[0].text\n",
    "        quartos = soup.find_all('span',attrs={'class':'sc-bdVaJa eNFcTE'})[1].text\n",
    "        banheiros = soup.find_all('span',attrs={'class':'sc-bdVaJa eNFcTE'})[2].text\n",
    "        vaga = soup.find_all('span',attrs={'class':'sc-bdVaJa eNFcTE'})[3].text\n",
    "        andar = soup.find_all('span',attrs={'class':'sc-bdVaJa eNFcTE'})[4].text\n",
    "        mobilia = soup.find_all('span',attrs={'class':'sc-bdVaJa eNFcTE'})[6].text\n",
    "        aluguel = soup.find_all('span',attrs={'class':'ek9a7p-0 djWxJW sc-11qijje-0 iRCHiJ'})[0].text\n",
    "        condominio = soup.find_all('span',attrs={'class':'ek9a7p-0 djWxJW sc-11qijje-0 bkKyCN'})[0].text\n",
    "        iptu = soup.find_all('span',attrs={'class':'ek9a7p-0 djWxJW sc-11qijje-0 bkKyCN'})[1].text\n",
    "        preco_total = soup.find_all('span',attrs={'class':'ek9a7p-0 djWxJW sc-11qijje-0 iRCHiJ'})[1].text\n",
    "    \n",
    "    \n",
    "    \n",
    "        apartment = { \n",
    "                        'codigo' : cod,\n",
    "                        'endereco' : endereco,\n",
    "                        'tipo_imovel' : tipo_imovel,\n",
    "                        'logradouro' : logradouro,\n",
    "                        'bairro' : bairro,\n",
    "                        'cidade' : cidade,\n",
    "                        'metragem' : metragem,\n",
    "                        'quartos': quartos,\n",
    "                        'banheiros': banheiros,\n",
    "                        'vaga': vaga,\n",
    "                        'andar' : andar,\n",
    "                        'mobilia' : mobilia,\n",
    "                        'aluguel': aluguel,\n",
    "                        'condominio' : condominio,\n",
    "                        'iptu' : iptu,\n",
    "                        'preco_total' : preco_total,\n",
    "                     }\n",
    "\n",
    "        list_apartment.append(apartment)   \n",
    "            \n",
    "            \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_apartment_raw = pd.DataFrame(list_apartment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the dataframe\n",
    "df_qa_apartment_raw.to_csv('../data/raw-data/df_qa_apartment_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loft - apartment for sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraping loft id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loft uses a code for every neighborhood where they have apartments\n",
    "neighborhood_loft = [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 171, 172, 173, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 196, 197, 198, 201, 203, 204, 207, 208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code apply for each neighborhood a search based in squared meter.\n",
    "#to improve, it is possible to get the next id recommendation in de soup\n",
    "\n",
    "start = 0\n",
    "finish = 1\n",
    "\n",
    "list_loft_id = []\n",
    "\n",
    "\n",
    "for num_neighborhood in neighborhood:\n",
    "    #print(num_neighborhood)\n",
    "    \n",
    "    for x in range(1000):\n",
    "        #print(start , finish)\n",
    "\n",
    "        url = f\"https://www.loft.com.br/apartamentos/sao-paulo-sp?neighbourhood=[{num_neighborhood}]&footage=[{start},{finish}]\"\n",
    "        response = requests.get(url)\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        start += 2\n",
    "        finish += 2\n",
    "\n",
    "        card_positions = len(soup.find_all('div', attrs={'data-testid': 'home-card'}))\n",
    "        for card in range(card_positions):\n",
    "            list_loft_id.append(soup.find_all('div', attrs={'data-testid': 'home-card'})[card].get('id'))\n",
    "\n",
    "        #print(list_loft_id)start = 0\n",
    "finish = 1\n",
    "\n",
    "list_loft_id = []\n",
    "\n",
    "\n",
    "for num_neighborhood in neighborhood:\n",
    "    #print(num_neighborhood)\n",
    "    \n",
    "    for x in range(1000):\n",
    "        #print(start , finish)\n",
    "\n",
    "        url = f\"https://www.loft.com.br/apartamentos/sao-paulo-sp?neighbourhood=[{num_neighborhood}]&footage=[{start},{finish}]\"\n",
    "        response = requests.get(url)\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        start += 2\n",
    "        finish += 2\n",
    "\n",
    "        card_positions = len(soup.find_all('div', attrs={'data-testid': 'home-card'}))\n",
    "        for card in range(card_positions):\n",
    "            list_loft_id.append(soup.find_all('div', attrs={'data-testid': 'home-card'})[card].get('id'))\n",
    "\n",
    "        #print(list_loft_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_loft_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_id = pd.DataFrame(list_loft_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_id.to_csv(r'../data/raw-data/df_loft_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  scraping apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_id = pd.read_csv(r'../data/raw-data/df_loft_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code extract the data apartment using the id previously collected\n",
    "df_loft_apartament = pd.DataFrame()\n",
    "for id_loft_ap in df_loft_id['0']:\n",
    "    \n",
    "    try:\n",
    "        url_apartment_buy = f'https://www.loft.com.br/home/{id_loft_ap}'\n",
    "        response = requests.get(url_apartment_buy)\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "\n",
    "        data_apartment = json.loads(soup.find_all('script', attrs={'id':\"__NEXT_DATA__\"})[0].contents[0])['props']['pageProps']['home']\n",
    "        df1 = pd.DataFrame.from_dict(data_apartment, orient='index').T\n",
    "        df_loft_apartament = df_loft_apartament.append(df1, ignore_index=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_apartament.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_apartament2 = df_loft_apartament[['id', 'type', 'area', 'bedrooms', 'suits', 'parkingSpots', 'floor', 'complexFee', 'propertyTax', 'price',  'address', 'amenities','currentPhase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = df_loft_apartament2['address'].apply(lambda x : pd.Series(x))\n",
    "df_loft_raw = pd.concat([df_loft_apartament2, addresses], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_raw['id_site'] = df_loft_raw.iloc[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_raw = df_loft_raw[['id_site', 'type', 'area', 'bedrooms', 'suits', 'parkingSpots', 'floor', 'complexFee', 'propertyTax', 'price', 'amenities', 'currentPhase','lat', 'lng', 'city', 'number', 'postalCode', 'streetName', 'streetType', 'unitNumber', 'neighborhood']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_raw.to_csv(r'../data/raw-data/df_loft_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google - palces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading api_key\n",
    "fkey = open('config.txt', 'r')\n",
    "api_key = fkey.read()\n",
    "gmaps = googlemaps.Client(key = api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loft_neigh = pd.read_csv(r'data/df_loft_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of neighborhood to find geolocation\n",
    "list_loft_neighborhood = []\n",
    "for x in loft['bairro'].unique():\n",
    "    list_loft_neighborhood.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#busca a geolocalização do bairro para buscar os pontos dele. \n",
    "#Para a busca utilizei apenas o ponto central do bairro para agilizar a busca. Utilizei uma distância que englobaria praticamente todo bairro\n",
    "bairro_latitude = {}\n",
    "for bairro in lista_bairros_loft:\n",
    "    try:\n",
    "        lat_lgn_bairro = gmaps.geocode(address = f'bairro + {bairro} ')[0]['geometry']['location']\n",
    "        bairro_latitude[bairro] = lat_lgn_bairro\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crio um dataframe com o bairro e sua latitude e longitude\n",
    "df1 = pd.DataFrame(bairro_latitude.values())\n",
    "df2 = pd.DataFrame(bairro_latitude.keys())\n",
    "df_bairros =pd.concat([df1, df2], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupei os serviços para agilizar a quantidade de buscas\n",
    "lugares_alimentacao = ['bakery', 'bar', 'cafe', 'restaurant']\n",
    "lugares_servicos = ['bank','beauty_salon','dentist','gym','laundry','lawyer']\n",
    "lugares_comercio = ['shopping','supermarket','loja de roupas','drugstore', 'florist','posto de gasolina','estacioanemtno','farmácia'  ]\n",
    "lugares_cultura = ['museum']\n",
    "lugares_saude = ['doctor','hospital']\n",
    "lugares_educacao = ['library','primary_school','school','secondary_school','university']\n",
    "lugares_transporte = ['bus_station']\n",
    "lugares_religiosos = ['church', 'cemetery','synagogue']\n",
    "lugares_governamentais = ['fire_station','police','post_office']\n",
    "lugares_parques = ['park']\n",
    "lugares_estadios = ['stadium']\n",
    "lugares_metro_trem = ['estação de metrô','estação de trem']\n",
    "lugares_turismo = ['tourist_attraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listo as categorias que vou buscar no places\n",
    "lista_query = [lugares_alimentacao, lugares_servicos, lugares_comercio, lugares_cultura, lugares_saude, lugares_educacao,\n",
    "               lugares_transporte, lugares_religiosos, lugares_governamentais, lugares_parques, lugares_estadios, \n",
    "               lugares_metro_trem, lugares_turismo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lista_locations = []\n",
    "lista_locations = list(zip(df_bairros['lat'], df_bairros['lng']))\n",
    "len(lista_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lugares_google = []\n",
    "location = 0\n",
    "for locations in lista_locations:\n",
    "    location += 1 #para ver se o cogigo esta rodando\n",
    "    print(location)\n",
    "    for item_query in lista_query:\n",
    "\n",
    "        params = {\n",
    "            'query': item_query,\n",
    "            'location': locations,\n",
    "            'radius': 2000,\n",
    "            'open_now' : False\n",
    "        }\n",
    "\n",
    "\n",
    "        x = gmaps.places(**params)\n",
    "\n",
    "        lugares_google.append(x['results'])\n",
    "\n",
    "        for pagina in range(2):\n",
    "            try:\n",
    "                params['page_token'] = x['next_page_token'] \n",
    "                time.sleep(2)\n",
    "                x = gmaps.places(**params)\n",
    "                lugares_google.append(x['results'])\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_places2 = pd.DataFrame(lugares_google[0])\n",
    "for lista_lugares in lugares_google:\n",
    "    df_google_places2 = df_google_places2.append(lista_lugares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_places2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_places2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_places2.to_csv(r'../data/raw-data/df_google_places2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180.355px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
